{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trofimov_BBMO-01-24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAN0G-6jrcpU",
        "outputId": "da542888-4d76-432d-f815-2a93ca27dbf3",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np  # Импорт библиотеки NumPy для работы с массивами и математическими операциями.\n",
        "import pandas as pd  # Импорт библиотеки Pandas для работы с данными в формате таблиц (DataFrame).\n",
        "import matplotlib as mpl  # Импорт библиотеки Matplotlib для визуализации данных.\n",
        "import matplotlib.pyplot as plt  # Импорт модуля pyplot из Matplotlib для создания графиков.\n",
        "import seaborn as sns  # Импорт библиотеки Seaborn для улучшенной визуализации данных.\n",
        "import string  # Импорт модуля string для работы со строками.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Импорт TfidfVectorizer для преобразования текстовых данных в векторы.\n",
        "from sklearn.model_selection import train_test_split  # Импорт функции для разделения данных на обучающую и тестовую выборки.\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Импорт CountVectorizer для преобразования текстов в матрицы частот.\n",
        "from sklearn import preprocessing  # Импорт модуля для предварительной обработки данных.\n",
        "from nltk.stem import SnowballStemmer  # Импорт стеммера Snowball для обработки текстов.\n",
        "from nltk.tokenize import RegexpTokenizer  # Импорт токенизатора для разбиения текста на токены.\n",
        "from nltk.corpus import stopwords  # Импорт списка стоп-слов для фильтрации.\n",
        "from nltk.stem.porter import *  # Импорт стеммера Портера для обработки текстов.\n",
        "import nltk  # Импорт библиотеки Natural Language Toolkit (NLTK) для обработки естественного языка.\n",
        "nltk.download('stopwords')  # Загрузка списка стоп-слов из NLTK.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JYfWY6BosKQ6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')  # Загружает данные из CSV файла 'spam.csv' с указанной кодировкой.\n",
        "le = preprocessing.LabelEncoder()  # Создает экземпляр LabelEncoder для преобразования категориальных меток в числовой формат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "q3Kxk8x9sdXj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "data = df.to_numpy()  # Преобразует DataFrame df в массив NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CQ7z-5n9sge9",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X = data[:, 1]  # Извлекает все строки и второй столбец из массива данных, который содержит признаки (например, текст сообщений).\n",
        "y = data[:, 0]  # Извлекает все строки и первый столбец из массива данных, который содержит метки (например, \"spam\" или \"ham\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCIVTx6Ysggm",
        "outputId": "19217084-769a-4af6-85ed-5b086b6bf9bd",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5572,), (5572,))"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape  # Возвращает размеры массивов X и y."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e7ZpFSZvsgqE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tokenizer = RegexpTokenizer('\\w+')  # Создает токенизатор, который разделяет текст на слова, игнорируя знаки препинания.\n",
        "sw = set(stopwords.words('english'))  # Загружает набор стоп-слов на английском языке и преобразует его в множество для быстрого поиска.\n",
        "ps = PorterStemmer()  # Инициализирует стеммер Портера для приведения слов к их корневой форме."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "KfOsXqgcsgtq",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#позволяет улучшить качество анализа и классификации текстов\n",
        "def getStem(review):\n",
        "    review = review.lower()  # Приводит текст отзыва к нижнему регистру.\n",
        "    tokens = tokenizer.tokenize(review)  # Разбивает текст на токены (слова).\n",
        "    removed_stopwords = [w for w in tokens if w not in sw]  # Удаляет стоп-слова из токенов.\n",
        "    stemmed_words = [ps.stem(token) for token in removed_stopwords]  # Приводит оставшиеся слова к их корневой форме.\n",
        "    clean_review = ' '.join(stemmed_words)  # Объединяет очищенные слова обратно в строку.\n",
        "    return clean_review  # Возвращает очищенный и обработанный отзыв."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "PjtP4dNGsgxj",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Функция для получения очищенных документов\n",
        "def getDoc(document):\n",
        "    d = []  # Создаем пустой список для хранения очищенных документов\n",
        "    for doc in document:  # Проходим по каждому документу в переданном списке\n",
        "        d.append(getStem(doc))  # Очищаем документ с помощью функции getStem и добавляем его в список\n",
        "    return d  # Возвращаем список очищенных документов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UiD7bPEfsgo8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Получаем очищенные документы, применяя функцию getDoc к массиву X\n",
        "stemmed_doc = getDoc(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6X2GSJXsgmq",
        "outputId": "cb33f2b7-1dd3-49e1-edb6-fc64abe45bf0",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat',\n",
              " 'ok lar joke wif u oni',\n",
              " 'free entri 2 wkli comp win fa cup final tkt 21st may 2005 text fa 87121 receiv entri question std txt rate c appli 08452810075over18',\n",
              " 'u dun say earli hor u c alreadi say',\n",
              " 'nah think goe usf live around though',\n",
              " 'freemsg hey darl 3 week word back like fun still tb ok xxx std chg send ã â 1 50 rcv',\n",
              " 'even brother like speak treat like aid patent',\n",
              " 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press 9 copi friend callertun',\n",
              " 'winner valu network custom select receivea ã â 900 prize reward claim call 09061701461 claim code kl341 valid 12 hour',\n",
              " 'mobil 11 month u r entitl updat latest colour mobil camera free call mobil updat co free 08002986030']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Выводим первые 10 очищенных и стеммированных документов\n",
        "stemmed_doc[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p17dxL_zsgkp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "cv = CountVectorizer() # преобразует коллекцию текстовых документов в числовую матрицу, где строки представляют документы,\n",
        "# а столбцы — уникальные слова (или токены) из этих документов. Каждый элемент матрицы указывает, сколько раз соответствующее слово встречается в документе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3xEOvVs-s3Uz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Создание словаря с помощью CountVectorizer\n",
        "vc = cv.fit_transform(stemmed_doc)\n",
        "#Создание словаря позволяет определить уникальные слова, которые будут использоваться для представления текстовых данных в числовом формате."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jIYvFfTNs5sA",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X = vc.todense() # преобразует разреженную матрицу, созданную с помощью CountVectorizer, в плотную матрицу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xSNI8pdjs5uF",
        "tags": []
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) # разделяем на обучающую и тестовую выборки, 33% данных будут отведены для тестирования, а оставшиеся 67% — для обучени\n",
        "#random_state=42: Этот параметр устанавливает начальное значение генератора случайных чисел, что позволяет воспроизводить результаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "SNFPDN0Vs53j",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Импортирование класса MultinomialNB из библиотеки sklearn\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "# модель наивного байесовского классификатора, что позволит вам классифицировать новые документы на основе обученных данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOsrenTNs57y",
        "outputId": "dbb93cb2-3f44-4e7c-d4ac-8070189d2e1a",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.977705274605764"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# Создание экземпляра модели наивного байесовского классификатора\n",
        "model = MultinomialNB()\n",
        "\n",
        "# Обучение модели на обучающем наборе данных\n",
        "model.fit(np.asarray(X_train), y_train)\n",
        "\n",
        "# Оценка точности модели на тестовом наборе данных\n",
        "model.score(np.asarray(X_test), y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "n8-Rtl_Ys513",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# приглашения и уведомления о различных мероприятиях в области технологий. Каждое сообщение адресовано конкретному получателю и содержит информацию о мероприятиях, таких как хакатоны и технические семинары\n",
        "messages = [\n",
        "    \"\"\"\n",
        "    Hi Kunal,\n",
        "We invite you to participate in MishMash - India’s largest online diversity hackathon.\n",
        "The hackathon is a Skillenza initiative and sponsored by Microsoft, Unity, Unilever, Gojek, Rocketium and Jharkhand Government.\n",
        "We have a special theme for you - Deep Tech/Machine Learning - sponsored by Unilever, which will be perfect for you.\n",
        "    \"\"\",\n",
        "    \"\"\"Join us today at 12:00 PM ET / 16:00 UTC for a Red Hat DevNation tech talk on AWS Lambda and serverless Java with Bill Burke.\n",
        "Have you ever tried Java on AWS Lambda but found that the cold-start latency and memory usage were far too high?\n",
        "In this session, we will show how we optimized Java for serverless applications by leveraging GraalVM with Quarkus to\n",
        "provide both supersonic startup speed and a subatomic memory footprint.\"\"\",\n",
        "\n",
        "    \"\"\"We really appreciate your interest and wanted to let you know that we have received your application.\n",
        "There is strong competition for jobs at Intel, and we receive many applications. As a result, it may take some time to get back to you.\n",
        "Whether or not this position ends up being a fit, we will keep your information per data retention policies,\n",
        "so we can contact you for other positions that align to your experience and skill set.\n",
        "\"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SvViQfDvs5zX",
        "tags": []
      },
      "outputs": [],
      "source": [
        "#преобразовать обработанные документы в матрицу частот слов.\n",
        "def prepare(messages):\n",
        "    d = getDoc(messages)\n",
        "    # dont do fit_transform!! it will create new vocab.\n",
        "    return cv.transform(d)\n",
        "messages = prepare(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu76hOSPs5x2",
        "outputId": "b4c65d20-88cd-490f-e885-c6ad182d8196",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ham', 'spam', 'ham'], dtype='<U4')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# В этом коде используется метод predict модели model,\n",
        "# чтобы сделать предсказания на основе подготовленных сообщений, которые были переданы в функцию prepare. Это позволяет модели классифицировать каждое сообщение в соответствии с обученными категориями\n",
        "y_pred = model.predict(messages)\n",
        "y_pred\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
